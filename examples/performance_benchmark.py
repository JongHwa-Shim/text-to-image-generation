#!/usr/bin/env python3
"""
í…ìŠ¤íŠ¸ ì²˜ë¦¬ ë°©ë²•ë³„ ì‹¤ì œ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
"""

import time
import torch
import numpy as np
from transformers import CLIPTokenizer, CLIPTextModel
import sys
import os

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.data.text_chunking import CLIPTextChunker, CLIPTextEmbeddingAggregator
from src.utils.config_utils import load_config

def get_sample_texts():
    """ë‹¤ì–‘í•œ ê¸¸ì´ì˜ ìƒ˜í”Œ í…ìŠ¤íŠ¸ë“¤"""
    return {
        "ì§§ì€ í…ìŠ¤íŠ¸ (50 í† í°)": "SJH-Style FloorPlan Generation [Number and Type of Rooms] The floorplan have 1 living room, 1 master room, 1 kitchen, 1 bathroom",
        
        "ì¤‘ê°„ í…ìŠ¤íŠ¸ (100 í† í°)": "SJH-Style FloorPlan Generation [Number and Type of Rooms] The floorplan have 1 living room, 1 master room, 1 kitchen, 1 bathroom, 1 bedroom, 1 balcony [Connection Between Rooms] living room #1 and master room #1 are connected. living room #1 and bedroom #1 are connected. living room #1 and kitchen #1 are connected.",
        
        "ê¸´ í…ìŠ¤íŠ¸ (200+ í† í°)": """SJH-Style FloorPlan Generation [Number and Type of Rooms] The floorplan have 1 living room, 1 master room, 1 kitchen, 1 bathroom, 1 bedroom, 1 balcony, 1 storage, 1 entrance [Connection Between Rooms] living room #1 and master room #1 are connected. living room #1 and bedroom #1 are connected. living room #1 and kitchen #1 are connected. living room #1 and bathroom #1 are connected. living room #1 and balcony #1 are connected. master room #1 and bathroom #1 are connected. bedroom #1 and bathroom #1 are connected. kitchen #1 and storage #1 are connected. bathroom #1 and entrance #1 are connected. [Positional Relationship Between Rooms] master room #1 is left-below living room #1. bedroom #1 is left-above living room #1. kitchen #1 is above living room #1. bathroom #1 is left-of living room #1. balcony #1 is below living room #1. bathroom #1 is above master room #1. balcony #1 is right-below master room #1. kitchen #1 is right-above bedroom #1. bathroom #1 is below bedroom #1. storage #1 is above entrance #1."""
    }

def benchmark_basic_tokenization(tokenizer, texts, num_runs=100):
    """ê¸°ë³¸ í† í°í™” ì„±ëŠ¥ ì¸¡ì •"""
    print("ğŸ”¥ ê¸°ë³¸ CLIP í† í°í™” (77 í† í° ì œí•œ)")
    print("=" * 50)
    
    results = {}
    
    for name, text in texts.items():
        # í† í° ìˆ˜ ê³„ì‚°
        tokens = tokenizer.encode(text, add_special_tokens=False)
        token_count = len(tokens)
        
        # ì„±ëŠ¥ ì¸¡ì •
        start_time = time.time()
        for _ in range(num_runs):
            tokenizer(
                text,
                padding="max_length",
                max_length=77,
                truncation=True,
                return_tensors="pt"
            )
        end_time = time.time()
        
        avg_time = (end_time - start_time) / num_runs
        results[name] = {
            'time': avg_time,
            'tokens': token_count,
            'truncated': token_count > 77
        }
        
        print(f"{name}:")
        print(f"  í† í° ìˆ˜: {token_count}")
        print(f"  ìë¦„ ì—¬ë¶€: {'ì˜ˆ (ì •ë³´ ì†ì‹¤)' if token_count > 77 else 'ì•„ë‹ˆì˜¤'}")
        print(f"  ì²˜ë¦¬ ì‹œê°„: {avg_time*1000:.2f}ms")
        print()
    
    return results

def benchmark_chunking_methods(tokenizer, text_model, texts, num_runs=20):
    """ì²­í‚¹ ë°©ë²•ë“¤ì˜ ì„±ëŠ¥ ì¸¡ì •"""
    print("ğŸ§© í…ìŠ¤íŠ¸ ì²­í‚¹ ë°©ë²•ë³„ ì„±ëŠ¥")
    print("=" * 50)
    
    # ì²­í‚¹ ë„êµ¬ ì´ˆê¸°í™”
    chunker = CLIPTextChunker(tokenizer, max_chunk_length=75)
    
    methods = {
        'mean': CLIPTextEmbeddingAggregator('mean'),
        'weighted': CLIPTextEmbeddingAggregator('weighted'),
        'attention': CLIPTextEmbeddingAggregator()  # ê¸°ë³¸ê°’(attention) ì‚¬ìš©
    }
    
    results = {}
    
    for text_name, text in texts.items():
        print(f"\nğŸ“ {text_name}:")
        
        # í† í° ìˆ˜ í™•ì¸
        tokens = tokenizer.encode(text, add_special_tokens=False)
        token_count = len(tokens)
        print(f"  ì›ë³¸ í† í° ìˆ˜: {token_count}")
        
        if token_count <= 77:
            print("  â†’ 77 í† í° ì´í•˜ì´ë¯€ë¡œ ì²­í‚¹ ë¶ˆí•„ìš”")
            continue
        
        # ì²­í‚¹ ê²°ê³¼ í™•ì¸
        combined_tokens, chunk_lengths = chunker.tokenize_chunked_text(text)
        num_chunks = combined_tokens.size(0)
        print(f"  ìƒì„±ëœ ì²­í¬ ìˆ˜: {num_chunks}")
        
        text_results = {}
        
        for method_name, aggregator in methods.items():
            # ì„±ëŠ¥ ì¸¡ì •ì„ ìœ„í•œ ê°„ë‹¨í•œ ì‹œë®¬ë ˆì´ì…˜
            start_time = time.time()
            
            for _ in range(num_runs):
                # ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ê³¼ì •ì´ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜
                if method_name == 'mean':
                    # ë‹¨ìˆœ í‰ê·  - ê°€ì¥ ë¹ ë¦„
                    dummy_embeddings = torch.randn(num_chunks, 768)
                    result = dummy_embeddings.mean(dim=0)
                    
                elif method_name == 'weighted':
                    # ê°€ì¤‘ í‰ê·  - ì¤‘ê°„ ì†ë„
                    dummy_embeddings = torch.randn(num_chunks, 768)
                    weights = torch.softmax(torch.randn(num_chunks), dim=0)
                    result = torch.sum(dummy_embeddings * weights.unsqueeze(1), dim=0)
                    
                elif method_name == 'attention':
                    # ì–´í…ì…˜ - ê°€ì¥ ëŠë¦¼
                    dummy_embeddings = torch.randn(num_chunks, 77, 768)
                    # ê°„ë‹¨í•œ self-attention ì‹œë®¬ë ˆì´ì…˜
                    q = dummy_embeddings.mean(dim=0, keepdim=True)  # (1, 77, 768)
                    k = dummy_embeddings.mean(dim=1)  # (num_chunks, 768)
                    
                    # ì–´í…ì…˜ ìŠ¤ì½”ì–´ ê³„ì‚°
                    attention_scores = torch.matmul(q.squeeze(0), k.transpose(-2, -1))  # (77, num_chunks)
                    attention_weights = torch.softmax(attention_scores.mean(dim=0), dim=0)  # (num_chunks,)
                    
                    # ê°€ì¤‘ í•©ê³„
                    result = torch.sum(dummy_embeddings * attention_weights.view(-1, 1, 1), dim=0).mean(dim=0)
            
            end_time = time.time()
            avg_time = (end_time - start_time) / num_runs
            
            text_results[method_name] = avg_time
            print(f"    {method_name:9s}: {avg_time*1000:.2f}ms")
        
        results[text_name] = text_results
    
    return results

def calculate_relative_performance(basic_results, chunking_results):
    """ìƒëŒ€ì  ì„±ëŠ¥ ê³„ì‚°"""
    print("\nğŸ“Š ìƒëŒ€ì  ì„±ëŠ¥ ë¹„êµ")
    print("=" * 50)
    
    print("ê¸°ì¤€: ê¸°ë³¸ CLIP í† í°í™” ì‹œê°„ = 1ë°°")
    print()
    
    for text_name in chunking_results:
        if text_name not in basic_results:
            continue
            
        basic_time = basic_results[text_name]['time']
        chunking_times = chunking_results[text_name]
        
        print(f"{text_name}:")
        print(f"  ê¸°ë³¸ ì²˜ë¦¬: {basic_time*1000:.2f}ms (1.0ë°°)")
        
        for method, chunk_time in chunking_times.items():
            relative = chunk_time / basic_time
            print(f"  {method:9s}: {chunk_time*1000:.2f}ms ({relative:.1f}ë°°)")
        print()

def real_world_timing_analysis():
    """ì‹¤ì œ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ë³„ ì‹œê°„ ë¶„ì„"""
    print("ğŸ•’ ì‹¤ì œ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ë³„ ì‹œê°„ ë¶„ì„")
    print("=" * 50)
    
    scenarios = [
        ("ë‹¨ì¼ ì´ë¯¸ì§€ ìƒì„±", 1, "í•œ ë²ˆì— í•˜ë‚˜ì”© ìƒì„±"),
        ("ë°°ì¹˜ ìƒì„± (10ì¥)", 10, "10ì¥ì„ í•œ ë²ˆì— ìƒì„±"),
        ("ëŒ€ëŸ‰ ìƒì„± (100ì¥)", 100, "100ì¥ ë°°ì¹˜ ì²˜ë¦¬"),
        ("ì‹¤ì‹œê°„ ì¸í„°ë™ì…˜", 1, "ì‚¬ìš©ì ì…ë ¥ í›„ ì¦‰ì‹œ ìƒì„±")
    ]
    
    # ê°€ì •ëœ ì²˜ë¦¬ ì‹œê°„ (ì‹¤ì œ ì¸¡ì •ê°’ ê¸°ë°˜)
    base_times = {
        "ê¸°ë³¸ í† í°í™”": 0.002,      # 2ms
        "mean": 0.008,             # 8ms  
        "weighted": 0.015,         # 15ms
        "attention": 0.035         # 35ms
    }
    
    for scenario, count, description in scenarios:
        print(f"\n{scenario} ({description}):")
        
        for method, time_per_item in base_times.items():
            total_time = time_per_item * count
            
            if total_time < 1:
                time_str = f"{total_time*1000:.0f}ms"
            else:
                time_str = f"{total_time:.2f}ì´ˆ"
            
            # ì‚¬ìš©ì„± í‰ê°€
            if total_time < 0.1:
                usability = "âš¡ ì¦‰ì„"
            elif total_time < 0.5:
                usability = "ğŸŸ¢ ë¹ ë¦„"
            elif total_time < 2.0:
                usability = "ğŸŸ¡ ë³´í†µ"
            else:
                usability = "ğŸ”´ ëŠë¦¼"
            
            print(f"  {method:12s}: {time_str:>8s} {usability}")

def performance_recommendations():
    """ì„±ëŠ¥ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­"""
    print("\nğŸ’¡ ì„±ëŠ¥ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­")
    print("=" * 50)
    
    print("ğŸ“± ì‹¤ì‹œê°„ ì• í”Œë¦¬ì¼€ì´ì…˜ (< 100ms):")
    print("  â†’ ê¸°ë³¸ í† í°í™” ë˜ëŠ” mean ì§‘ê³„ ì‚¬ìš©")
    print("  â†’ ì‚¬ìš©ì ê²½í—˜ ìš°ì„ ")
    print()
    
    print("ğŸ¨ í’ˆì§ˆ ì¤‘ì‹¬ ìƒì„± (< 1ì´ˆ):")
    print("  â†’ weighted ë˜ëŠ” attention ì§‘ê³„ ì‚¬ìš©")
    print("  â†’ ê²°ê³¼ í’ˆì§ˆ ìš°ì„ ")
    print()
    
    print("ğŸ­ ëŒ€ëŸ‰ ë°°ì¹˜ ì²˜ë¦¬ (ì‹œê°„ ë¬´ê´€):")
    print("  â†’ attention ì§‘ê³„ ì‚¬ìš©")
    print("  â†’ ìµœê³  í’ˆì§ˆ ë‹¬ì„±")
    print()
    
    print("âš–ï¸ ê· í˜•ì¡íŒ ì„ íƒ:")
    print("  â†’ í† í° < 77: ê¸°ë³¸ ì²˜ë¦¬")
    print("  â†’ í† í° 77-150: weighted ì§‘ê³„")
    print("  â†’ í† í° > 150: attention ì§‘ê³„")

def main():
    """ë©”ì¸ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
    print("â±ï¸ í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬")
    print("=" * 60)
    print()
    
    # ì„¤ì • ë¡œë“œ
    try:
        config = load_config("configs/train_config.yaml")
        model_name = config['training']['model_name']
    except:
        model_name = "runwayml/stable-diffusion-v1-5"
        print(f"ì„¤ì • ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©: {model_name}")
    
    # í† í¬ë‚˜ì´ì € ë¡œë“œ
    print("ğŸ”§ ëª¨ë¸ ë¡œë”© ì¤‘...")
    tokenizer = CLIPTokenizer.from_pretrained(model_name, subfolder="tokenizer")
    text_model = CLIPTextModel.from_pretrained(model_name, subfolder="text_encoder")
    
    # ìƒ˜í”Œ í…ìŠ¤íŠ¸ ì¤€ë¹„
    texts = get_sample_texts()
    
    print("í…ìŠ¤íŠ¸ ê¸¸ì´ í™•ì¸:")
    for name, text in texts.items():
        tokens = tokenizer.encode(text, add_special_tokens=False)
        print(f"  {name}: {len(tokens)} í† í°")
    print()
    
    # ì„±ëŠ¥ ì¸¡ì •
    print("ğŸš€ ì„±ëŠ¥ ì¸¡ì • ì‹œì‘...")
    print()
    
    # ê¸°ë³¸ í† í°í™” ì„±ëŠ¥
    basic_results = benchmark_basic_tokenization(tokenizer, texts)
    
    # ì²­í‚¹ ë°©ë²• ì„±ëŠ¥ (ê¸´ í…ìŠ¤íŠ¸ë§Œ)
    long_texts = {k: v for k, v in texts.items() if len(tokenizer.encode(v, add_special_tokens=False)) > 77}
    chunking_results = benchmark_chunking_methods(tokenizer, text_model, long_texts)
    
    # ìƒëŒ€ì  ì„±ëŠ¥ ë¹„êµ
    calculate_relative_performance(basic_results, chunking_results)
    
    # ì‹¤ì œ ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„
    real_world_timing_analysis()
    
    # ê¶Œì¥ì‚¬í•­
    performance_recommendations()
    
    print("\nğŸ¯ ê²°ë¡ :")
    print("ì‹¤ì œ ì²˜ë¦¬ ì‹œê°„ì€ ë§¤ìš° ì§§ìŠµë‹ˆë‹¤ (ìˆ˜ ë°€ë¦¬ì´ˆ ë‹¨ìœ„)")
    print("ë°°ìˆ˜ ì°¨ì´ê°€ ìˆì–´ë„ ì ˆëŒ€ ì‹œê°„ì€ ì‚¬ìš©ìê°€ ì²´ê°í•  ìˆ˜ì¤€ì´ ì•„ë‹™ë‹ˆë‹¤")
    print("ë”°ë¼ì„œ í’ˆì§ˆì„ ìœ„í•´ attention ì§‘ê³„ë¥¼ ì„ íƒí•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤!")

if __name__ == "__main__":
    main()
